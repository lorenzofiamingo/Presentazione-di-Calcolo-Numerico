\documentclass[10pt]{beamer}

\usecolortheme{dove}
\definecolor{mycyan}{rgb}{0.2157, 0.7059, 0.9608}
\setbeamercolor{alerted text}{fg=mycyan}
\setbeamertemplate{bibliography item}{\insertbiblabel}
\setbeamertemplate{caption}[numbered]
\hypersetup{colorlinks,linkcolor=,urlcolor=mycyan}
\usepackage{animate,xcolor,colortbl,listings,nicefrac}
\usepackage[italian]{babel}

\usepackage{listings}
\lstset{upquote=false}
\usepackage[]{framed}
\begin{document}


\begin{frame}
  \title{Metodi di Krylov}
  \subtitle{Metodi per la soluzione numerica di equazioni lineari non simmetriche applicabili in un sottospazio di Krylov.}
  \date{29/04/2020}
  \author[Principal]{Fabio Archenti \and Fabio Camagni \and Andrea Favero \and  \\Lorenzo Fiamingo \and Stefano Gallivanone \and Nazariy Nashkolnyy}
  \maketitle
\end{frame}


\begin{frame}
    \frametitle{Bibliografia}
    
  \begin{thebibliography}{99}\small
    \bibitem{quarteroni2012calcolo}
    Quarteroni, Saleri, and Gervasio.
    \newblock {\em Calcolo Scientifico: Esercizi e problemi risolti con MATLAB e  Octave}.
    \newblock UNITEXT. Springer Milan, 2012.

    \bibitem{trefethen-bau}
    Trefethen, and Bau.
    \newblock {\em Numerical Linear Algebra}.
    \newblock SIAM, 1997.
    
   
   \bibitem{dac95}
   Telichevesky, Kundert, and White.
   \newblock {\em Efficient Steady-State Analysis based on Matrix-Free Krylov-Subspace Methods}.
   \newblock {\em Scientific report}, June 1995.

   \end{thebibliography}

%Una volta inserito un documento in bibliografia, 
%può essere citato così:~\cite{quarteroni2012calcolo}
  
\end{frame}  

\begin{frame}
  \frametitle{Sommario}
  %Questo comando inserisce una lista delle sezioni in
  %cui è divisa la presentazione. Perché una sezione appaia 
  %nel sommario deve contenere almeno una pagina.
  \tableofcontents
\end{frame}

\section{Introduzione}\label{sec:sec1}

\begin{frame} \frametitle{Introduzione}
\begin{itemize}
    \item I metodi di Krylov sono metodi iterativi utilizzati per risolvere sistemi lineari A$\mathbf{x}=\mathbf{b}$.

    \item Data una matrice A di dimensione $\mathit{n}$ e un vettore $\mathbf{v}\in \mathbb{R}^n$, si definisce \alert{sottospazio di Krylov} lo spazio
    $$
    \mathcal{K}_\mathrm{n}(A,\mathbf{v})=span\{\mathbf{v},A\mathbf{v},A^2\mathbf{v},\dots,A^{n-1}\mathbf{v}\}, n\geq1
    $$

    \item Ad ogni passo dell'iterazione viene calcolata una soluzione approssimata $\mathbf{x}^\mathit{n}$ appartenente al sottospazio di Krylov $\mathcal{K}_\mathrm{n}(A,\mathbf{r}_0)$, dove $\mathbf{r}_0=\mathbf{b}-A\mathbf{x}_0$ è il vettore residuo al passo 0 e $\mathbf{x}_0$ è la soluzione calcolata al passo 0.
    
\end{itemize}
\end{frame}

\begin{frame} \frametitle{Metodi di Discesa}
\begin{itemize}
    \item Assegnato un $x_0\in \mathbb{R}^n$ si procede aumentando k = 0, 1, ... fino a convergenza:
    \begin{enumerate}
        \item determinando direzione di discesa $d_k \in \mathbb{R}^n$
        \item determinando passo $\alpha_k\in \mathbb{R}$
        \item ponendo $\mathbf{x}_{k+1}=\mathbf{x}_{k}+\alpha_k\mathbf{d}_{k}$
    \end{enumerate}
    \item Una direzione di discesa per una funzione $\phi$ (in un punto x generico) è un vettore d tale che:
    \begin{enumerate}
        \item $d^T\nabla\phi(x) < 0$ se $\nabla\phi(x)  != 0$
        \item d = 0      se $\nabla\phi(x) = 0$
    \end{enumerate}
    \item I Metodi del Gradiente e Gradiente Coniugato sono metodi di discesa che usano lo stesso $\alpha_k$ ma due direzioni di discesa differenti
\end{itemize}
\end{frame}

\section{Metodo del Gradiente Coniugato}\label{sec:sec2}

\begin{frame} \frametitle{Metodo del Gradiente Coniugato (I)}
\begin{itemize}
    \item Data A matrice simmetrica e definita positiva, possiamo definire la funzione (forma quadratica) $\phi:\mathbb{R}^n \to \mathbb{R}$ $$\phi(\mathbf{x})=\frac{1}{2}\mathbf{x}^TA\mathbf{x}-\mathbf{x}^T\mathbf{b}.$$
    
    \item Questa funzione (se le ipotesi su A sono verificate) è convessa e ammette un unico punto $\mathbf{x}^{\ast}$ di minimo assoluto.
    
    \item $\nabla \phi(\mathbf{x})=A\mathbf{x}-\mathbf{b}$. Nel punto $\mathbf{x}^{\ast}$ il gradiente si annulla: 
    $\nabla \phi(\mathbf{x}^{\ast})=A\mathbf{x}^{\ast}-\mathbf{b}=\mathbf{0}$.
    Risolvere il problema di minimo (trovando $\mathbf{x}^{\ast}$) equivale quindi a risolvere il sistema A$\mathbf{x}=\mathbf{b}$.

\end{itemize}
\end{frame}

\begin{frame} \frametitle{Metodo del Gradiente Coniugato (II)}
\begin{itemize}
    \item Per minimizzare $\phi(\mathbf{x})$, partendo da una \alert{guess} iniziale $x_0$, dobbiamo scegliere una \alert{direzione di discesa} $\mathbf{d}_{k}$ (ovvero un vettore $\in \mathbb{R}^n$) e un \alert{passo di discesa} $\alpha_k$ (con $\alpha_k \in \mathbb{R}$) ponendo $\mathbf{x}_{k+1}=\mathbf{x}_{k}+\alpha_k\mathbf{d}_{k}$.
    
    \item Scegliamo ad ogni passo una direzione A-ortogonale rispetto a tutte le direzioni precedenti, cioè tale che $(A\mathbf{d}_{j})^T\mathbf{d}_{k+1}=\mathbf{0}$ e $(\mathbf{r}_{k+1})^T\mathbf{d}_j=\mathbf{0}$ $j=0,\dots,k$.
    
    \item All'inizio $\mathbf{d}_0=\mathbf{r}_0$, poi $(\mathbf{d}_{k+1})=\mathbf{r}_{k+1}-\beta_k\mathbf{d}_k$ per $k=0,\dots,n-1$, con $\beta_k=\frac{(A\mathbf{d}_{k})^T\mathbf{r}_{k+1}}{(A\mathbf{d}_{k})^T\mathbf{d}_{k}}$ (scelta ottimale).
    
    \item In questo modo le $\mathbf{d}_k$ sono linearmente indipendenti e la soluzione $\mathbf{x}_{k+1}$ è ottimale rispetto a tutte le direzioni di discesa (ovvero $\mathbf{r}_{k+1}$ è ortogonale a $\mathbf{d}_k$): è garantito che $\mathbf{x}_n=\mathbf{x}^{\ast}$.
\end{itemize}
\end{frame}


\begin{frame} \frametitle{Passo di discesa}
\begin{itemize}
\item Il passo di discesa più convenient è $\alpha=...$
\item Dimostrazione:
\begin{itemize}
    \item La soluzione al passo $k+1$ è $\mathbf{x}_{k+1}=\mathbf{x}_{k}+\alpha_k\mathbf{d}_{k}$
    \item Sostituendo nella forma quadratica
    \end{itemize}

\end{itemize}
\end{frame}

\section{GMRES}\label{sec:sec3}

\begin{frame} \frametitle{GMRES}
\begin{itemize}
    \item \textbf{GMRES} (General Minimal RESidual) è uno dei metodi di Krylov utilizzato per risolvere il sistema lineare $Ax = b$ tramite il sottospazio
    $\mathcal{K}_\mathrm{n}$ in modo tale da rendere minima la norma Euclidea del residuo: $$\|\mathbf{b}-A\mathbf{x_n}\|_2.$$
    
    \item Sia $K_n$ la matrice $m x n$ di Krylov, composta da spazi colonne A$\mathcal{K}_\mathrm{n}$. Inanzitutto si moltiplica $K_n$ per A, per cui il problema diventa trovare un vettore $\mathbf{c}\in\mathbb{C}^n$, tale per cui il residuo $\|AK_n\mathbf{c}-\mathbf{b}\|_2$ sia minimo. 
    
    \item Questa formula è risolvibile con fattorizzazione QR, ma $AK_n$ diventa \textbf{numericamente instabile} al crescere di $n$, quindi si utilizza \alert{l'iterazione di Arnoldi} per costruire una base di vettori ortonormali.

\end{itemize}
\end{frame}

\begin{frame} \frametitle{L'iterazione di Arnoldi (I)}
\begin{itemize}
    \item Si definisce $Q_n$ come la matrice, i cui vettori formano una base di $\mathcal{K}_\mathrm{n}$. Il problema consiste ora nella ricerca di $\mathbf{y}\in\mathbb{C}^n$ tale per cui: $$\|AQ_n\mathbf{y}-\mathbf{b}\|_2 = minimo,$$ riducendo così le dimensioni del problema da $m x n$ a $(n+1) x n$.
    
    \item L'iterazione di Arnoldi dimostra che $AQ_n = Q_{n+1}\mathcal{H}_n$ (con $\mathcal{H}_n$ la matrice alta-sinistra, $(n+1) x n$, della matrice di Hessenberg). Il problema quindi diventa:$$\|Q_n\mathcal{H}_n\mathbf{y}-\mathbf{b}\|_2 = minimo.$$ 

\end{itemize}
\end{frame}

\begin{frame} \frametitle{L'iterazione di Arnoldi (II)}
\begin{itemize}
    \item Moltiplicando entrambi i membri per $Q^*_{n+1}$ si ottiene: $$\|\mathcal{H}_n\mathbf{y}-Q^*_{n+1}\mathbf{b}\|_2 = minimo.$$
    
    \item Si osserva che $Q^*_{n+1}\mathbf{b}=\|\mathbf{b}\|\mathbf{e_1}$, con $\mathbf{e_1}=(1,0,0,\dots)^*$, quindi il problema 
    finale è:$$\|\mathcal{H}_n\mathbf{y}-\|\mathbf{b}\|\mathbf{e_1}\|_2 = minimo.$$ Questa equazione è risolvibile con l'approssimazione ai minimi quadrati.

\end{itemize}
\end{frame}

\begin{frame} \frametitle{GMRES Polinomi}
\begin{itemize}
    \item Il metodo GMRES è utilizzabile anche nel calcolo polinomiale.
    
    \item Dato $p_n\in P_n$, con $p_n(0)=1$ si definisce $x_n=q_n(A)\mathbf{b}$ e $r_n=p_n(A)\mathbf{b}$. Il problema consiste nel calcolare $p_n\in P_n$ tale che $$\|r_n\|=minimo.$$

\end{itemize}
\end{frame}

\begin{frame} \frametitle{Velocità di convergenza}\framesubtitle{Quanto deve valere \textbf{n} (numero di iterazioni) per soddisfare la tolleranza?}
    $$ \frac{\|r_n\|}{\|\mathbf{b}\|}  < tolleranza$$
\begin{itemize}
    \item Osservazione 1: convergenza monotona $\|r_{n+1}\|\leq \|r_n\|$.
    \item Osservazione 2: per $n\to \infty$, $\|r_{\infty} \|= 0$, a meno di errori di arrotondamento.
    
    \item Essendo $\|r_n\| = \|p_n(A)\|\|\mathbf{b}\|$ risulta che solo $p_n(A)$ influenza la velocità di convergenza: $$\frac{\|r_n\|}{\|\mathbf{b}\|} \leq inf\|p_n(A)\|,$$ con $p_n \in P_n$.

\end{itemize}
\end{frame}


\begin{frame} \frametitle{Come inserire una formula}
Una formula può essere inserita all'interno del testo così : 
$-\nabla \left( \varepsilon \nabla u \right) = f $ oppure 
centrata e numerata così:
\begin{equation}\label{eq:poisson}
    -\nabla \cdot \left( \varepsilon \nabla u \right) = f
\end{equation}
oppure centrata senza numerazione così :
$$
 -\nabla \cdot \left( \varepsilon \nabla u \right) = f
$$
Posso fare riferimento alle formule numerate così : \eqref{eq:poisson}
\end{frame}

\begin{frame} \frametitle{Come inserire una lista per punti}
Ecco come inserire una lista per punti
\begin{itemize}
    \item un punto
    \item un altro
\end{itemize}
oppure un elenco numerato
\begin{enumerate}
    \item primo punto
    \item secondo punto
\end{enumerate}

\end{frame}



\begin{frame} \frametitle{Come inserire un pezzo di codice}
Si può evidenziare \alert{parte del testo} in questo modo.
%
Si può inserire un comando matlab all'interno del testo
in questo modo : \lstinline[language=Matlab]{for i = 1 : 10, disp (i), end}

si può inserire un un file contenete un codice matlab in questo modo :
\lstinputlisting[language=Matlab]{codice.m}

Si possono inserire solo alcune righe del file in questo modo :
\lstinputlisting[language=Matlab, firstline=1, lastline=2]{codice.m}

\end{frame}



\begin{frame} \frametitle{Come inserire una figura}
Questo è un esempio di come inserire una figura
\begin{figure}
    \centering
    \includegraphics[width=.75\linewidth]{iv.pdf}
    \caption{Questa è la didascalia}
    \label{fig:my_label}
\end{figure}
Se la figura ha un'etichetta la si può usare per fare riferimento
alla figura nel testo : Figura~\ref{fig:my_label}
\end{frame}

\begin{frame} \frametitle{Altra documentazione}
Questo è un esempio di come inserire un link ad un URL
\begin{itemize}
    \item Altre informazioni utili
    \begin{itemize}
        \item Il sito del \href{https://www.latex-project.org}{\LaTeX{}--project}
            \begin{itemize}
                \item Una lista di 
                \href{https://www.latex-project.org/get}{software offline ed online}\\
                per creare documenti \LaTeX{}
            \end{itemize}
        \item Un \href{https://en.wikibooks.org/wiki/LaTeX}{Wikibook} su \LaTeX
        \begin{itemize}
            \item La sezione sulle \href{https://en.wikibooks.org/wiki/LaTeX/Presentations}
            {presentazioni}
            \item La sezione sulle
            \href{https://en.wikibooks.org/wiki/LaTeX/Mathematics}{formule}
        \end{itemize}
        \item Un \href{https://tex.stackexchange.com/}{forum} con domande e risposte
        \item La documentazione di \href{https://it.overleaf.com/learn}{overleaf}
        \begin{itemize}
            \item Un \href{https://it.overleaf.com/learn/latex/Learn_LaTeX_in_30_minutes}
            {tutorial} per iniziare in 30 minuti
        \end{itemize}
        \item Uno strumento per \href{http://detexify.kirelabs.org/classify.html}
        {cercare simboli}
    \end{itemize}
\end{itemize}
\end{frame}
\end{document}
